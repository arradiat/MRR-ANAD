---
title: "Mame Diarra Toure-Nisrine Moummou TP1 MRR 2019"
output:
  pdf_document: 
  html_document:
    df_print: paged
fontsize: 6pt
geometry: margin=1.2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\color{magenta}\section{I.Facebook data}
\color{black}
As data Scientists we are asked to study the dataset "facebookdata.txt" in order to forecast the number of facebook users 2 months after the last month available in the data set
\color{red}\subsection{1.Preliminary work}
\color{black}
First of all we start with uploading the data and plotting it to see if there is a tendency and then we will compute the correlation matrix.

\tiny
```{r,include=FALSE}
library(corrplot)
```

```{r,echo=FALSE,fig.height=3,out.width='50%',fig.show='hold'}
ftab<-read.table(file="/Users/princessemame/Downloads/Files/TP1/facebookdata.txt",sep=";",header=TRUE)
plot(ftab,pch = 16, col = "purple")
corrplot(cor(ftab))
```
\normalsize
If we look closer to this plot we see that the number of facebook users grows exponentially in relation  to months 
Thanks to the function cor we compute the correlation matrix and see that there is a strong correlation between the target: the number of users and the covaraibles: months
\color{red}\subsection{2.Regression Model}
\color{black}
Since the plot showed that the number of users grows exponentially in relation to months we are going transform the data in order to have a linar relation between our two variables.To do so we are going to use the function $f(x)=log(x+1)$.
Indeed, to avoid having $\infty$ on the first row we use log(x+1) instead of log(x)\\
\tiny
```{r,echo=FALSE,fig.height=3,fig.width=8,fig.align='left'}
logftab=ftab
logftab[,2]=log(ftab[,2]+1)
plot(log(ftab),type='l',cex.lab=0.75,cex.main=0.75)
```
\normalsize
We see now that the logarithm of users has a linear relation with the months. We can then use a linear regression model in order to forecast the number of users in the futur.
\color{red}\subsection{3.Linear regression Model}
\color{black}
Let $Y$ be our target variable represented here by the log of the number of users
and $X$ our co variable represented here by the number of months .
Our linear model is the following $Y=\beta_1+ \beta_2X$
We are going to use the lm function in order to compute the estimated values for the coefficients $\beta_1$  and $\beta_2$
\tiny
```{r,echo=FALSE,fig.height=3,fig.width=3,fig.show='hold',results='hold',out.width='50%',out.height='30%'}
fcbkreg<-lm(users~.,data=logftab)
fcbkreg
summary(fcbkreg)
```
\normalsize
We obtain $\beta_1=0.6124$ and $\beta_2=0.0856$
Hence $Y=0.6124+ 0.0856X$
\color{blue}\subsubsection{3.1 P-values}
\color{black}
Starting with the p-values, typically, we use the coefficient's p-values to determine which terms to keep in the regression model. 
The p-value for each term tests the null hypothesis that the coefficient is equal to zero. A low p-value (< 0.05 or <0.01 according to the confident levels) indicates that you can reject the null hypothesis. In other words, a predictor that has a low p-value is likely to be a meaningful addition to your model.
In the output above, we can see that the predictor variables of months  is significant because its p-value is realy close to  0. 
The p-value of the intercept is also small but bigger than the p-value of months thus it is less significant to our model. 
\color{blue}\subsubsection{3.2 R-squared and adjusted R-squared}
\color{black}
Geometrically  the R-squared is the cosinus of the angle between the centered vector and its centered prediction
In other words it shows how much the estimation is close to the reality.
The closer it is to 1 the better the superimposition of the two vectors is.
The adjusted R-squared means the same thing only it is not affected by the number of co-variables.
Here we have R-squared =0.9707,	Adjusted R-squared =0.9683
meaning that our model is really close to reality.
\color{blue}\subsubsection{Plot of $\hat Y$ function of Y}
\color{black}
\tiny
```{r,echo=FALSE,fig.show='hold',fig.height=3,fig.width=3}
Y_hat<-0.61243+0.08562*logftab$mois
rY<-exp(Y_hat)-1
res <- ftab$users - rY
```
```{r,fig.show='hold',fig.height=3,out.width='50%'}
plot(ftab$users,rY)
abline(0,1,col="red")
grid()
plot(ftab$users,res,ylim = c(-20,40))
```
\normalsize
As we see it our model gives a good explanation of the data. Indeed the points are really close to the  the first bissectrix $y=x$ except for the last point which is separated from the others. We can also see that our residuals seems to follow a random distribution. \color{red}
However we think that the divergence of the last point compromise strongly our future predictions
\color{black}
\color{red}\subsection{4- Forecasting}
\color{black}
Now we are going to forecast the number of facebook users in 2 months using the function predict
\tiny
```{r,echo=FALSE}
predict(fcbkreg,newdata = data.frame(mois=c(80)),interval="confidence")
```
\normalsize
We have $log(number of facebook users+1)=7.462004$
Hence the Number of facebook users in two months is equal to $\exp(7.462004)-1$
\boxed{Number of facebook users in two months=1739.633}
However, due to the divergence of the last point of our estimation, We can't be sure about this prediction, adding to that we are pretty suspicious about the fact that the number of users increased by almost 1000 in 2 months 
\color{magenta}\section{II.UScrime data}
\color{black}
As data Scientists we are asked to study the dataset "UScrime" which contain 16 variables in order to study from a predictive point of view the ability of a linear model to model the target variable: the crime rate
\color{red}\subsection{1.Preliminary work}
\color{black}
First of all we start with uploading the data and computing the correlation matrix.
```{r,include=FALSE}
library(corrplot)
library(MASS)
```
\tiny
```{r,echo=FALSE}
data(UScrime)
corrplot(cor(UScrime), method="circle")
```
\normalsize
\newline The correlation plot shows us that our target variable is not correlated to all the covariables, hence a linear model containing all the 15 covariable may not be the best choice here.
We also notice that some of the co-variables are strongly correlated to each other (Po1 and GDP for exemple),thus they shouldn't be both on the model. 
\color{red}\subsection{2.Liear Regression Model containing all the p covariables }
\color{black}
Let's start by assuming that all covariables are important to our linear model and see what we obtain
\tiny
```{r,echo=FALSE,fig.height=3,fig.width=3,fig.show='hold',results='hold',out.width='50%',out.height='30%'}
crimereg=lm(y~.,data=UScrime)
summary(crimereg)
```
\normalsize
We notice that only 5 of the covariables have a p-value smaller than 0.05. Hence for those ones the null hypothesis is not rejected, those are the coefficients that are likely to be meaningful to our model.
Yet,if we plot the estimated target in relation to the observed target we see that the point are close to the bissextrix meaning that our model is close to the reality. The Adjusted R-squared, which is equal to \color{red} 0.7078, is indeed quite close to 1 \color{black},
The value of the residuals,however random, are quite important leading us to doubt this model.

```{r,echo=FALSE,fig.height=3,fig.width=6,fig.show='hold',results='hold',out.width='50%',out.height='30%'}
X=as.matrix(cbind(rep(1,length(47)),UScrime[,1:15]))
beta=t(t(crimereg$coefficients))
Y_hat=X%*%beta
plot(UScrime$y,Y_hat,pch=16,col='purple')
abline(0,1,col="red")
grid()
plot(UScrime$y,crimereg$residuals,pch=16,col='purple')
```

\color{red}\subsection{2.Ttraining and testing our model}
\color{black}
We think that using all the covariables in our model is not good and we should probably do a forward selection for exemple to select the important ones.
However in order to be sure about that we are going to split our dataset into a training dataset and a testing dataset and see if we obtain a good prediction or not.
To do so we are going to split randomly our dataset several times. And for each time we are going to compute the RMSE on the test data and on the training data( cross validattion). We, then plot the two boxplots to evaluate our model.

```{r,echo= FALSE}
rmse1=c()
rmse2=c()
for (i in 1:20){
## 75% of the sample size
smp_size <- floor(0.75 * nrow(UScrime))

## set the seed to make your partition reproducible
set.seed(4500*(120*i))
train_ind<- sample(seq_len(nrow(UScrime)), size = smp_size)

tabtrain <- UScrime[train_ind, ]
tabtest <- UScrime[-train_ind, ]
modreg1=lm(y~., data=tabtrain)

rmse1[i]=sqrt((sum(modreg1$residuals**2))/length(tabtrain))
ytest=predict(modreg1,newdata=tabtest[,1:15],interval='confidence')
y_predicted=data.frame(ytest)$fit
y_predicted
y=tabtest$y
res1=y-y_predicted
rmse2[i]=sqrt((sum(res1**2))/length(tabtest))

}
boxplot(rmse1,rmse2,col=(c("purple","pink")))
grid()
```

Cross-validation is the process of assessing how the results of a statistical analysis will generalize to an independent data set. If the model has been estimated over some, but not all, of the available data, then the model using the estimated parameters can be used to predict the held-back data. If, for example, the out-of-sample mean squared error, also known as the mean squared prediction error, is substantially higher than the in-sample mean square error, this is a sign of deficiency in the model.\newline The boxplots above show us that the range of the RMSE  of the testing dataset is  really wide compared to the RMSE of the training dataset.
The RMSE of the test dataset goes from approximatively 180 to 280. So it changes considerably from a given sample to another menaning that we can't be confident about our model predictions.
We also notice that the median of RMSE is higher for the test dataset than for the training dataset.In general the RMSE obtaine on the testing dataset is bigger than the RMSE obtained with the training dataset. Hence we can assume that there is deficiency in our model. 
\bf \color{blue}In conclusion , from a predictive point of view, we think that a linear model containing all the 15 covariables is not able to model our target variable

```{r,echo=FALSE,include=F}
R1=rep(1,20)
R2=rep(2,20)
R=c(R1,R2)
R=as.factor(R)
rmse=c(rmse1,rmse2)
tab=cbind(rmse,R)
tab <- data.frame(tab)
library(ggplot2)
a <- ggplot(tab,aes(y=rmse,group=R)) +geom_boxplot(notch=F, outlier.color = "red", outlier.shape = 8, outlier.size = 4,fill = "lightgray", color = "black")
a
```



